{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nicole0906/DLI_Group_Assignment/blob/main/Nicole_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TQQffc1Ndvnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0f1aef-4878-4c2c-b5f4-929eaa974b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Change directory to the desired location in Google Drive\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning Model"
      ],
      "metadata": {
        "id": "eFArG0Pdw0Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 1: Install dependencies\n",
        "# ==============================\n",
        "!pip install -q xgboost scikit-learn tabulate gdown\n",
        "\n",
        "# ==============================\n",
        "# STEP 2: Imports & Reproducibility\n",
        "# ==============================\n",
        "import os, random, time, subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tabulate import tabulate\n",
        "\n",
        "# ---- Reproducibility: set ALL the seeds ----\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ==============================\n",
        "# STEP 3: Fetch & Load dataset from GitHub\n",
        "# ==============================\n",
        "REPO_URL = \"https://github.com/Nicole0906/DLI_Group_Assignment.git\"\n",
        "CLONE_DIR = \"./DLI_Group_Assignment\"\n",
        "\n",
        "if not os.path.exists(CLONE_DIR):\n",
        "    print(f\"‚¨áÔ∏è  Cloning repository from: {REPO_URL}\")\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, CLONE_DIR], check=True)\n",
        "\n",
        "DATA_PATH = os.path.join(CLONE_DIR, \"Phishing_Legitimate_full 3.csv\")\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print(\"‚úÖ Dataset loaded successfully!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# ==============================\n",
        "# STEP 4: Define features & target\n",
        "# ==============================\n",
        "TARGET_COL = \"CLASS_LABEL\"\n",
        "ID_COLS = [c for c in [\"id\"] if c in df.columns]\n",
        "\n",
        "X = df.drop(columns=ID_COLS + [TARGET_COL])\n",
        "y = df[TARGET_COL]\n",
        "\n",
        "print(\"\\nFeature shape:\", X.shape)\n",
        "print(\"Target distribution:\\n\", y.value_counts())\n",
        "\n",
        "unique_labels = sorted(y.unique())\n",
        "label_map = {0: \"Legitimate\", 1: \"Phishing\"}\n",
        "for lbl in unique_labels:\n",
        "    if lbl not in label_map:\n",
        "        label_map[lbl] = f\"Class {lbl}\"\n",
        "\n",
        "# ==============================\n",
        "# STEP 5: Train-test split (seeded)\n",
        "# ==============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nData Split:\")\n",
        "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
        "\n",
        "# ==============================\n",
        "# STEP 6: Train Tuned XGBoost Model\n",
        "# ==============================\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=700,          # more trees\n",
        "    learning_rate=0.03,        # slower learning\n",
        "    max_depth=7,               # deeper trees\n",
        "    max_leaves=80,             # more leaves\n",
        "    subsample=0.95,            # more samples per tree\n",
        "    colsample_bytree=0.95,     # more features per tree\n",
        "    gamma=0.1,                 # minimal loss reduction\n",
        "    min_child_weight=2,        # min sum of instance weight per child\n",
        "    random_state=SEED,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Training Tuned XGBoost model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ==============================\n",
        "# STEP 7: Evaluate the tuned model\n",
        "# ==============================\n",
        "start = time.time()\n",
        "y_pred = model.predict(X_test)\n",
        "end = time.time()\n",
        "inference_time = (end - start) / len(X_test) * 1000.0  # ms/sample\n",
        "\n",
        "print(\"\\nüìä Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "\n",
        "# ==============================\n",
        "# STEP 8: Build Custom Evaluation Table\n",
        "# ==============================\n",
        "classes = sorted(unique_labels)\n",
        "table_rows = []\n",
        "for cls in classes:\n",
        "    cls_key = str(cls)\n",
        "    if cls_key in report:\n",
        "        table_rows.append([\n",
        "            f\"{cls} ({label_map.get(cls, f'Class {cls}')})\",\n",
        "            round(report[cls_key][\"precision\"], 3),\n",
        "            round(report[cls_key][\"recall\"], 3),\n",
        "            round(report[cls_key][\"f1-score\"], 3),\n",
        "            int(report[cls_key][\"support\"]),\n",
        "            round(inference_time, 3),\n",
        "        ])\n",
        "\n",
        "# Accuracy, Macro avg, Weighted avg\n",
        "table_rows.extend([\n",
        "    [\"Accuracy\", round(report[\"accuracy\"], 3)]*3 + [len(y_test), round(inference_time, 3)],\n",
        "    [\"Macro avg\", round(report[\"macro avg\"][\"precision\"], 3),\n",
        "     round(report[\"macro avg\"][\"recall\"], 3),\n",
        "     round(report[\"macro avg\"][\"f1-score\"], 3),\n",
        "     int(report[\"macro avg\"][\"support\"]), round(inference_time, 3)],\n",
        "    [\"Weighted avg\", round(report[\"weighted avg\"][\"precision\"], 3),\n",
        "     round(report[\"weighted avg\"][\"recall\"], 3),\n",
        "     round(report[\"weighted avg\"][\"f1-score\"], 3),\n",
        "     int(report[\"weighted avg\"][\"support\"]), round(inference_time, 3)]\n",
        "])\n",
        "\n",
        "print(\"\\nüìë Tuned Evaluation Table:\\n\")\n",
        "print(tabulate(\n",
        "    table_rows,\n",
        "    headers=[\"Class\", \"Precision\", \"Recall\", \"F1-score\", \"Support\", \"Inference Time (ms/sample)\"],\n",
        "    tablefmt=\"grid\"\n",
        "))\n",
        "\n",
        "# ==============================\n",
        "# STEP 9: Print Final F1 Score + Verdict\n",
        "# ==============================\n",
        "final_f1 = round(report[\"weighted avg\"][\"f1-score\"], 3)\n",
        "TARGET_F1 = 0.98\n",
        "verdict = \"target met ‚úÖ\" if final_f1 >= TARGET_F1 else \"target not met ‚ùå\"\n",
        "print(f\"\\nüéØ Final F1 Score: {final_f1}\")\n",
        "print(f\"‚úÖ Verdict: Achieved F1 = {final_f1}, target = {TARGET_F1} ‚Üí {verdict}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpmfDVR5w34O",
        "outputId": "6b9cbac9-3f77-472d-ec37-8dc6bd25cc07"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset loaded successfully!\n",
            "Shape: (10000, 50)\n",
            "Columns: ['id', 'NumDots', 'SubdomainLevel', 'PathLevel', 'UrlLength', 'NumDash', 'NumDashInHostname', 'AtSymbol', 'TildeSymbol', 'NumUnderscore', 'NumPercent', 'NumQueryComponents', 'NumAmpersand', 'NumHash', 'NumNumericChars', 'NoHttps', 'RandomString', 'IpAddress', 'DomainInSubdomains', 'DomainInPaths', 'HttpsInHostname', 'HostnameLength', 'PathLength', 'QueryLength', 'DoubleSlashInPath', 'NumSensitiveWords', 'EmbeddedBrandName', 'PctExtHyperlinks', 'PctExtResourceUrls', 'ExtFavicon', 'InsecureForms', 'RelativeFormAction', 'ExtFormAction', 'AbnormalFormAction', 'PctNullSelfRedirectHyperlinks', 'FrequentDomainNameMismatch', 'FakeLinkInStatusBar', 'RightClickDisabled', 'PopUpWindow', 'SubmitInfoToEmail', 'IframeOrFrame', 'MissingTitle', 'ImagesOnlyInForm', 'SubdomainLevelRT', 'UrlLengthRT', 'PctExtResourceUrlsRT', 'AbnormalExtFormActionR', 'ExtMetaScriptLinkRT', 'PctExtNullSelfRedirectHyperlinksRT', 'CLASS_LABEL']\n",
            "\n",
            "Feature shape: (10000, 48)\n",
            "Target distribution:\n",
            " CLASS_LABEL\n",
            "1    5000\n",
            "0    5000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Data Split:\n",
            "Train size: (8000, 48) Test size: (2000, 48)\n",
            "\n",
            "üöÄ Training Tuned XGBoost model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [17:16:24] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Confusion Matrix:\n",
            " [[988  12]\n",
            " [ 13 987]]\n",
            "\n",
            "üìë Tuned Evaluation Table:\n",
            "\n",
            "+----------------+-------------+----------+------------+-----------+------------------------------+\n",
            "| Class          |   Precision | Recall   |   F1-score | Support   |   Inference Time (ms/sample) |\n",
            "+================+=============+==========+============+===========+==============================+\n",
            "| 0 (Legitimate) |       0.987 | 0.988    |      0.988 | 1000      |                        0.042 |\n",
            "+----------------+-------------+----------+------------+-----------+------------------------------+\n",
            "| 1 (Phishing)   |       0.988 | 0.987    |      0.987 | 1000      |                        0.042 |\n",
            "+----------------+-------------+----------+------------+-----------+------------------------------+\n",
            "| Accuracy       |       0.988 | Accuracy |      0.988 | Accuracy  |                        0.988 |\n",
            "+----------------+-------------+----------+------------+-----------+------------------------------+\n",
            "| Macro avg      |       0.988 | 0.988    |      0.987 | 2000      |                        0.042 |\n",
            "+----------------+-------------+----------+------------+-----------+------------------------------+\n",
            "| Weighted avg   |       0.988 | 0.988    |      0.987 | 2000      |                        0.042 |\n",
            "+----------------+-------------+----------+------------+-----------+------------------------------+\n",
            "\n",
            "üéØ Final F1 Score: 0.987\n",
            "‚úÖ Verdict: Achieved F1 = 0.987, target = 0.98 ‚Üí target met ‚úÖ\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}