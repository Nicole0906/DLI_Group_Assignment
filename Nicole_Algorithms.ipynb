{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nicole0906/DLI_Group_Assignment/blob/main/Nicole_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TQQffc1Ndvnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256e33fb-491d-4328-ffff-e20ac9f53d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Change directory to the desired location in Google Drive\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning Model"
      ],
      "metadata": {
        "id": "eFArG0Pdw0Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, classification_report, confusion_matrix,\n",
        "    precision_score, recall_score, roc_auc_score\n",
        ")\n",
        "\n",
        "# --------------------\n",
        "# 1. Clone GitHub Repo\n",
        "# --------------------\n",
        "REPO_URL = \"https://github.com/YOUR_USERNAME/YOUR_REPO.git\"  # <-- change this\n",
        "CLONE_DIR = \"/content/DLI_Group_Assignment\"\n",
        "\n",
        "if not os.path.exists(CLONE_DIR):\n",
        "    !git clone {REPO_URL} {CLONE_DIR}\n",
        "\n",
        "# --------------------\n",
        "# 2. Find CSV file automatically\n",
        "# --------------------\n",
        "csv_file = None\n",
        "for root, dirs, files in os.walk(CLONE_DIR):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(\".csv\"):\n",
        "            csv_file = os.path.join(root, file)\n",
        "            break\n",
        "    if csv_file:\n",
        "        break\n",
        "\n",
        "if csv_file is None:\n",
        "    raise FileNotFoundError(\"No CSV file found in the repository.\")\n",
        "\n",
        "print(f\"âœ… Found CSV file: {csv_file}\")\n",
        "\n",
        "# --------------------\n",
        "# 3. Load dataset\n",
        "# --------------------\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "if \"CLASS_LABEL\" not in df.columns:\n",
        "    raise ValueError(\"Dataset must have 'CLASS_LABEL' column as target.\")\n",
        "\n",
        "X = df.drop(columns=[\"CLASS_LABEL\"])\n",
        "y = df[\"CLASS_LABEL\"]\n",
        "\n",
        "# --------------------\n",
        "# 4. Split dataset\n",
        "# --------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --------------------\n",
        "# 5. Pipeline: Scaling + Logistic Regression\n",
        "# --------------------\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logreg', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# --------------------\n",
        "# 6. Train & Measure Inference Time\n",
        "# --------------------\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "start_time = time.time()\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "end_time = time.time()\n",
        "\n",
        "inference_time_ms = (end_time - start_time) * 1000\n",
        "\n",
        "inference_time_ms = (end_time - start_time) * 1000\n",
        "\n",
        "# Metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Number of parameters in logistic regression\n",
        "num_params = np.prod(pipeline.named_steps['logreg'].coef_.shape) + pipeline.named_steps['logreg'].intercept_.shape[0]\n",
        "\n",
        "# Results\n",
        "print(\"\\nðŸ“Š Logistic Regression Model Results\")\n",
        "print(f\"Accuracy     : {acc:.6f}\")\n",
        "print(f\"Precision    : {precision:.6f}\")\n",
        "print(f\"Recall       : {recall:.6f}\")\n",
        "print(f\"F1-score     : {f1:.6f}\")\n",
        "print(f\"ROC-AUC      : {roc_auc:.6f}\")\n",
        "print(f\"Parameters   : {num_params}\")\n",
        "print(f\"Inference Time: {inference_time_ms:.3f} ms\")\n",
        "\n",
        "# Classification Report & Confusion Matrix\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=6))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpmfDVR5w34O",
        "outputId": "ddaf2617-fe41-4ccf-bd0e-cf4b78fc563b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Found CSV file: /content/DLI_Group_Assignment/Phishing_Legitimate_full 3.csv\n",
            "\n",
            "ðŸ“Š Logistic Regression Model Results\n",
            "Accuracy     : 0.999000\n",
            "Precision    : 0.999000\n",
            "Recall       : 0.999000\n",
            "F1-score     : 0.999000\n",
            "ROC-AUC      : 0.999978\n",
            "Parameters   : 50\n",
            "Inference Time: 7.621 ms\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.999000  0.999000  0.999000      1000\n",
            "           1   0.999000  0.999000  0.999000      1000\n",
            "\n",
            "    accuracy                       0.999000      2000\n",
            "   macro avg   0.999000  0.999000  0.999000      2000\n",
            "weighted avg   0.999000  0.999000  0.999000      2000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[999   1]\n",
            " [  1 999]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate  # install with: pip install tabulate\n",
        "\n",
        "# Create a table-like output\n",
        "headers = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC-AUC\", \"Params\", \"Inference (ms)\"]\n",
        "table_data = [[\n",
        "    \"Logistic Regression (TF-IDF)\",\n",
        "    f\"{acc:.3f}\",\n",
        "    f\"{precision:.3f}\",\n",
        "    f\"{recall:.3f}\",\n",
        "    f\"{f1:.3f}\",\n",
        "    f\"{roc_auc:.3f}\",\n",
        "    num_params,\n",
        "    f\"{inference_time_ms:.2f}\"\n",
        "]]\n",
        "\n",
        "print(\"\\nMODEL EVALUATION TABLE\")\n",
        "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q6zLdSRLtV8",
        "outputId": "2a470222-583d-42aa-d8d2-fb909e69f983"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL EVALUATION TABLE\n",
            "+------------------------------+------------+-------------+----------+-------+-----------+----------+------------------+\n",
            "| Model                        |   Accuracy |   Precision |   Recall |    F1 |   ROC-AUC |   Params |   Inference (ms) |\n",
            "+==============================+============+=============+==========+=======+===========+==========+==================+\n",
            "| Logistic Regression (TF-IDF) |      0.999 |       0.999 |    0.999 | 0.999 |         1 |       50 |             7.62 |\n",
            "+------------------------------+------------+-------------+----------+-------+-----------+----------+------------------+\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.999     0.999     0.999      1000\n",
            "           1      0.999     0.999     0.999      1000\n",
            "\n",
            "    accuracy                          0.999      2000\n",
            "   macro avg      0.999     0.999     0.999      2000\n",
            "weighted avg      0.999     0.999     0.999      2000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[999   1]\n",
            " [  1 999]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Get classification report as dictionary\n",
        "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Convert to DataFrame for nicer formatting\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "# Round values to 3 decimal places\n",
        "report_df = report_df.round(3)\n",
        "\n",
        "# Print nicely using tabulate\n",
        "print(\"\\nCLASSIFICATION REPORT\")\n",
        "print(tabulate(report_df, headers='keys', tablefmt='grid'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JadT27VgQdNS",
        "outputId": "5f529262-228d-4a5f-fa82-1ccc0323ce09"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CLASSIFICATION REPORT\n",
            "+--------------+-------------+----------+------------+-----------+\n",
            "|              |   precision |   recall |   f1-score |   support |\n",
            "+==============+=============+==========+============+===========+\n",
            "| 0            |       0.999 |    0.999 |      0.999 |  1000     |\n",
            "+--------------+-------------+----------+------------+-----------+\n",
            "| 1            |       0.999 |    0.999 |      0.999 |  1000     |\n",
            "+--------------+-------------+----------+------------+-----------+\n",
            "| accuracy     |       0.999 |    0.999 |      0.999 |     0.999 |\n",
            "+--------------+-------------+----------+------------+-----------+\n",
            "| macro avg    |       0.999 |    0.999 |      0.999 |  2000     |\n",
            "+--------------+-------------+----------+------------+-----------+\n",
            "| weighted avg |       0.999 |    0.999 |      0.999 |  2000     |\n",
            "+--------------+-------------+----------+------------+-----------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}